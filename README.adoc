= AsciiDoctor Literate Programming module
Giuseppe Bilotta <giuseppe.bilotta@gmail.com>
// Settings
:sectnums:
:icons: font
:toc: left
:stem:
// Styling
:source-highlighter: rouge
:source-language: ruby
// URLs
:url-asciidoctor: https://www.asciidoctor.org/
:url-eweb: http://eweb.sourceforge.net/
:url-mrt: http://repos.modelrealization.com/cgi-bin/fossil/mrtools/wiki?name=asciidoc+literate+programming

== What is this?

This is a (Ruby) module to add literate programming support in {url-asciidoctor}[AsciiDoctor].

== Why is this?

Previous effort to introduce literate programming features in the AsciiDoc format include
{url-eweb}[eWEB] and the {url-mrt}[Model Realization Tools]' `atangle` and `aweave` programs.
So why do we need another one?

More features:: most importantly, support the creation of multiple files from a single document, a feauture that is missing from the existing tools;

Syntax compatibility:: the existing tools have slightly different syntax;
the obvious solution to this is to https://xkcd.com/927/[introduce a new, incompatible syntax],
_but_ the actual plan is to also support the syntax from the other two tools.

Integration:: we hook directly into AsciiDoctor, allowing single-pass processing of a document to produce both the documentation and the source;
the plan is to also include cross-referencing and indexing for the code chunks (but this is not currently implemented).

== How is this?

The module is implemented as an https://docs.asciidoctor.org/asciidoctor.js/latest/extend/extensions/register/[Asciidoctor extension].
Since we are only interested in producing secondary outputs, we implement a `TreeProcessor`,
that will traverse the document tree to gather all listing blocks that define chunks.

.Main class definition
[source]
----
class LiterateProgrammingTreeProcessor < Asciidoctor::Extensions::TreeProcessor
  <<Class initialization>>
  <<Support methods>>
  <<Tangling methods>>
  <<Processing methods>>
end
----

which of course requires the `asciidoctor/extensions` Ruby module that defines the `Asciidoctor::Extensions::TreeProcessor` class.

.Requires
[source]
require 'asciidoctor/extensions'

Each chunk is identified by a title, and the corresponding source code may be split across multiple listing blocks.
The first time a chunk title is encountered (be it to define or to use it), it must be written out in full.
In all other circumstances, it may be shortened to any _unambiguous_ prefix followed by an ellipsis (three dots: `...`).

The processor stores chunks in a `Hash` that the title (a `String`) to the content
(an `Array` of ``String``s). We declare two such hashes: `@chunks` will hold the generic code chunks,
while `@roots` will hold _root chunks_, i.e. chunks that define the outer structure of
each output file generated during the <<tangling>> process.

Since the source code associated with a generic chunk can be spread out over multiple blocks,
we define a default value constructor for `@chunks`: this will simplify the
process of appending new lines to a value each time we come across a new block.

To assist in the handling of shortened chunk titles, we keep track of all the (full) titles we've come across
so far.

.Class init...
[source]
----
def initialize config
  super config # <1>
  @roots = Hash.new
  @chunks = Hash.new { |hash, key| hash[key] = [] }
  @chunk_names = Set.new
end
----
<1> Rember to call the initializer of the superclass, or the custom processor won't work!

We need a way to find the full title when given a shortened version. This is achieved simply by finding
the keys in `@chunks` that match the given prefix, which we obtain by removing the trailing ellipsis if present.
If no key is found, or if multiple keys are found, an appropriate exception is raised.

.Support...
[source]
----
def full_title string
  pfx = string.chomp("...")
  # nothing to do if title was not shortened
  return string if string == pfx
  hits = @chunk_names.find_all { |s| s.start_with? pfx }
  raise ArgumentError, "No chunk #{string}" if hits.length == 0
  raise ArgumentError, "Chunk title #{string} is not unique" if hits.length > 1
  hits.first
end
----

Chunks may reference other chunks.
This is achieved by putting `<<Chunk name (possibly shortened)>>` on a line of its own
(optionally surrounded by whitespace).
When processing chunks line by line, we may want to check if a particular line is a chunk reference,
and if so we'll want the full name of the chunk. This is achieved by the `is_chunk_ref` method:

.Support...
[source]
----
def is_chunk_ref line
  if line.match /^\s*<<(.*)>>\s*$/
    return full_title $1
  else
    return false
  end
end
----


=== Tangling [[tangling]]

Tangling is the process of “stitching together” all the code blocks, recursively following the
referenced chunks starting from the root chunk, for each file.

The recursive tangling of chunks is achieved by a method that takes as input a `File` object
(where data will be written), the name of the current chunk being processed,
the contents of the chunk itself (`Array` of lines), and finally
a `Set` holding the names of all the chunks we're in the middle of processing. The latter is needed
to avoid infinite recursions due to chunks cyclically refrencing each other.

.Tangling...
[source]
----
def recursive_tangle file, chunk_name, chunk, stack
  stack.add chunk_name
  chunk.each do |line|
    ref = is_chunk_ref line
    if ref
      # must not be in the stack
      raise RuntimeError, "Recursive reference to #{ref} from #{chunk_name}" if stack.include? ref
      # must be defined
      raise ArgumentError, "Found reference to undefined chunk #{ref}" unless @chunks.has_key? ref
      # TODO whitespace handling
      recursive_tangle file, ref, @chunks[ref], stack
    else
      file.puts line
    end
  end
  stack.delete chunk_name
end
----

This needs to be done for each root chunk defined by the document:

.Tangling...
[source]
----
def tangle
  @roots.each do |name, initial_chunk|
    File.open(name, 'w') do |f|
      recursive_tangle f, name, initial_chunk, Set[]
    end
  end
end
----

=== Collecting chunks

A single block is processed if it has `source` style, in which case
we append its lines to the `Array` of lines of the corresponding chunk.
We also need to determine its type (root or generic chunk) to choose where the chunk will be stored.

After appending the lines to the chunk, we also check if any line is a chunk reference,
in which case we “prime” the `@chunk_names`, to allow subsequent usage of the chunk name in shortened form.

.Processing...
[source]
----
def process_block block
  <<Determine chunk type and title, setting chunk_hash and chunk_title>>

    @chunk_names.add chunk_title

  # append the lines TODO preprocessor directives for file and line
  chunk_hash[chunk_title] += block.lines

  <<Check for references and prime the chunk names>>
end
----

A source block defines a generic chunk, unless it has the `output` attribute set,
in which case it's a root chunk:

.Determine...
[source]
----
chunk_hash = @chunks
if block.style == "source"
  # is this a root chunk?
  if block.attributes.has_key? 'output'
    <<Handle root chunk>>
  else
    # We use the block title (TODO up to the first full stop or colon) as chunk name
    title = block.attributes['title']
    chunk_title = full_title title
    # TODO override block title if it was a shorthand prefix
  end
else
  # TODO check if first line is <<title>>=
  return
end
----

For a root chunk, aside from setting `chunk_hash` and `chunk_title` appropriately,
we also verify that the same file name (i.e. title) is not already defined:

.Handle root chunk
[source]
----
chunk_hash = @roots
chunk_title = block.attributes['output']
raise ArgumentError, "Duplicate root chunk for #{chunk_title}" if chunk_hash.has_key?(chunk_title)
chunk_hash[chunk_title] = []
----

Regardless of the chunk type, we scan the lines of the block we're processing, and add any
referenced chunk name to `@chunk_names`:

.Check for references...
[source]
----
block.lines.each do |line|
  mentioned = is_chunk_ref line
  @chunk_names.add mentioned if mentioned
end
----

=== Document processing

The document as a whole is processed simply by processing all the listing blocks,
and <<tangling>> the output files:

.Processing...
[source]
----
def process doc
  doc.find_by context: :listing do |block|
    process_block block
  end
  tangle
  doc
end
----


=== The module

The complete module simply assembles what we've seen so far, and registers the extension
with Asciidoctor:

.The module structure
[source,output=literate-programming.rb]
----
<<Requires>>

<<Main class...>>

Asciidoctor::Extensions.register do
  tree_processor LiterateProgrammingTreeProcessor
end
----

